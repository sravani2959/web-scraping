# -*- coding: utf-8 -*-
"""TASK 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uPHnVdjGv6bZsBXrOjKlsch4gsOnh7bJ
"""

import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup

url_link= 'https://timesofindia.indiatimes.com/'

response = requests.get(url_link)

print(response.status_code)

Data_from_website = BeautifulSoup(response.content,"lxml")

Data_from_website

Data_from_website.find("a")

Data_from_website.find_all("a")

len(Data_from_website.find_all("a"))

Data_from_website.find_all("a")[11]

Data_from_website.find_all("a")[8].get_text()

Data_from_website.find_all("a")[8].get('href')

label_name = []
api_link = []
img_url=[]
descriptions=[]

for i in Data_from_website.find_all("a"):
  label_name.append(i.get_text())
  api_link.append(i.get("href"))
  img_tag=i.find('img')
  img_scr=img_tag.get('src') if img_tag else None
  img_url.append(img_scr)


dis_1=Data_from_website.find_all("p")
dis_2=Data_from_website.find_all("figcaption")
dis_3=Data_from_website.find_all("span")

for tag in dis_1 + dis_2 + dis_3:
    descriptions.append(tag.text)

descriptions

label_name

api_link

print(len(label_name))
print(len(api_link))
print(len(img_url))
print(len(descriptions))

min_length = min(len(label_name), len(api_link), len(img_url), len(descriptions))

label_name = label_name[:min_length]
api_link = api_link[:min_length]
img_url = img_url[:min_length]
descriptions = descriptions[:min_length]

df=pd.DataFrame({'Names':label_name, "links":api_link, "Image":img_url, "Description":descriptions})

df

df.to_csv("times_of_india.csv", index=False)